{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "import requests\n",
    "!pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all industries\n",
    "url_industries = \"https://www.messen.de/de/branchen\"\n",
    "\n",
    "page = requests.get(url_industries)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "if False:\n",
    "    # Example\n",
    "    \"\"\"\n",
    "    <ul class=\"nav nav-tabs nav-tabs-index\">\n",
    "        # letter selector\n",
    "    <div class=\"tab-content tab-content-index\">\n",
    "        <ul class=\"nav nav-pills nav-stacked\">\n",
    "            <li>\n",
    "                <a href=\"/de/1586/branche/50plus\" title=\"Messen 50plus\">\n",
    "                    #50plus\n",
    "                </a>\n",
    "\n",
    "    nachrichten = soup.findAll('ul', {'class':'list'})\n",
    "    links = []\n",
    "    for ul in nachrichten:\n",
    "        links.extend(ul.findAll('a'))\n",
    "    print len(links)\n",
    "    \"\"\"\n",
    "\n",
    "industries = []\n",
    "\n",
    "industries_list = soup.findAll('ul', {'class':'nav-pills'})\n",
    "for ind in industries_list:\n",
    "    for a in ind.findAll('a', href=True):\n",
    "        industry_name = a.contents[0]\n",
    "        industry_url = a['href']\n",
    "        # print(industry_name, industry_url)\n",
    "        industries.append(\"https://messen.de\" + industry_url)\n",
    "\n",
    "# print(industries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all industries\n",
    "\n",
    "tradefair_overview_urls = []\n",
    "\n",
    "# Open each industry page\n",
    "\n",
    "for industry in industries:\n",
    "# Example ID: Automessen 22\n",
    "\n",
    "    page = requests.get(industry)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # print(soup.prettify())\n",
    "\n",
    "    pagination = soup.find('ul', {'class':'pagination'})\n",
    "    if pagination == None:\n",
    "        max_page = 1\n",
    "    else:\n",
    "        page_num = \"\"\n",
    "        for num in pagination.findAll('a'):\n",
    "            if num.contents[0] != \"»\":\n",
    "                page_num = num.contents[0]\n",
    "                # print(page_num)\n",
    "        max_page = int(page_num)\n",
    "\n",
    "    #print(max_page)\n",
    "\n",
    "        \n",
    "    # Find number of pages\n",
    "    # example page 01: https://www.messen.de/de/1416/branche/bau-und-heimwerkerbedarf\n",
    "    # example page 02: https://www.messen.de/de/1416/branche/bau-und-heimwerkerbedarf?offset=25\n",
    "    # example page 10: https://www.messen.de/de/1416/branche/bau-und-heimwerkerbedarf?offset=225  (last page)\n",
    "    # offset = (page_number - 1) * 25\n",
    "\n",
    "    industry_pages = [industry]\n",
    "    for i in range(max_page):\n",
    "        offset = i * 25\n",
    "        # print(offset)\n",
    "        if i > 0:\n",
    "            industry_pages.append(industry + \"?offset=\" + str(offset))\n",
    "    \n",
    "    # print(industry_pages)\n",
    "    tradefair_overview_urls.extend(industry_pages)\n",
    "    \n",
    "    # better external save in case messen.de caps off access\n",
    "    for ind_page in industry_pages:\n",
    "        print(ind_page)\n",
    "        with open('tradefair_overview_urls.csv','a') as f:\n",
    "            f.write(ind_page + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all pages\n",
    "\n",
    "import re\n",
    "\n",
    "def get_messen(messen_url):\n",
    "\n",
    "    industry = re.search(\"branche\\/(.+?)\\/?(?:\\?offset|$)\", messen_url).group(1)\n",
    "\n",
    "    page = requests.get(messen_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    messen = soup.findAll('div', {'class':'messe'})\n",
    "\n",
    "    messe_list = []\n",
    "    for messe in messen:\n",
    "        # print(messe.prettify())\n",
    "\n",
    "        messe_name = \"\"\n",
    "        messe_url = \"\"\n",
    "        messe_img = \"\"\n",
    "        messe_date = \"\"\n",
    "        messe_dur = \"\"\n",
    "        messe_loc = \"\"\n",
    "        messe_sub = \"\"\n",
    "\n",
    "\n",
    "        if messe.find('div', {'class':'messename'}).find(\"a\").find(\"span\"):\n",
    "            messe_name = messe.find('div', {'class':'messename'}).find(\"a\").find(\"span\").text\n",
    "\n",
    "        if messe.find('div', {'class':'messename'}).find(\"a\"):\n",
    "            messe_url = \"https://messen.de\" + messe.find('div', {'class':'messename'}).find(\"a\")['href']\n",
    "        \n",
    "        if messe.find('div', {'class':'messelogo'}).find(\"a\").find(\"img\"):\n",
    "            messe_img = messe.find('div', {'class':'messelogo'}).find(\"a\").find(\"img\")['src']\n",
    "        \n",
    "        if messe.find('div', {'class':'messedatum'}).find('div', {'class':'unbekannt'}):\n",
    "            if messe.find('div', {'class':'messedatum'}).find('div', {'class':'unbekannt'}).text == \"nächster Termin steht noch nicht fest\":\n",
    "                messe_date = \"nächster Termin steht noch nicht fest\"\n",
    "            else: messe_date = \"unbekannt\"\n",
    "        else:\n",
    "            if messe.find('div', {'class':'datum'}):\n",
    "                messe_date = messe.find('div', {'class':'datum'}).text\n",
    "\n",
    "            if messe.find('div', {'class':'laufzeit'}):\n",
    "                messe_dur = messe.find('div', {'class':'laufzeit'}).text\n",
    "            \n",
    "            if messe.find('div', {'class':'termin-abgesagt-hinweis'}):\n",
    "                messe_dur = messe.find('div', {'class':'termin-abgesagt-hinweis'}).text\n",
    "            \n",
    "        if messe.find('div', {'class':'messeort'}):\n",
    "            messe_loc = messe.find('div', {'class':'messeort'}).text\n",
    "        \n",
    "        if messe.find('div', {'class':'messeuntertitel'}):\n",
    "            messe_sub = messe.find('div', {'class':'messeuntertitel'}).text # .text is better than .contents[0] as it handles zero-strings better\n",
    "\n",
    "        messe_list.append([messe_name, messe_loc, messe_date, messe_dur, messe_sub, messe_url, industry, messe_img])\n",
    "        \n",
    "    # print(messe_list)\n",
    "\n",
    "    if True:\n",
    "        # As backup append to .csv file\n",
    "        for mes in messe_list:\n",
    "            # print(mes)\n",
    "            with open('tradefair_overview.csv','a') as f:\n",
    "                wr = csv.writer(f, dialect='excel')\n",
    "                wr.writerow(mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in tradefair_overview_urls:\n",
    "    get_messen(url)\n",
    "# bei ausbildungsmessen unterbrochen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case requests were interupted, this helps you continue from a certain point\n",
    "for url in tradefair_overview_urls[105:200]:\n",
    "    get_messen(url)\n",
    "\n",
    "\n",
    "os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case requests were interupted, this helps you continue from a certain point\n",
    "# with timer\n",
    "\n",
    "start = time.time()\n",
    "with open('tradefair_overview.csv','r') as f:\n",
    "    count = sum(1 for line in f)\n",
    "\n",
    "for url in tradefair_overview_urls[1200:]:\n",
    "    get_messen(url)\n",
    "\n",
    "end = time.time()\n",
    "os.system('say \"your program has finished\"')\n",
    "\n",
    "with open('tradefair_overview.csv','r') as f:\n",
    "    print(sum(1 for line in f) - count, \" rows added in \", (end-start)/60, \"minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tradefair_overview_urls)"
   ]
  }
 ]
}